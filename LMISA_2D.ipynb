{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "# sys.path.append('git/_framework')\n",
    "from utils import util as U\n",
    "from core.data_provider import DataProvider\n",
    "from core.trainer_tf_uni import Trainer\n",
    "from core.data_processor import SimpleImageProcessor\n",
    "from core.learning_rate import StepDecayLearningRate\n",
    "from model.model_wgan_uni import GANModel\n",
    "from model.gan_10k import Generator, Discriminator\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "epochs = 1\n",
    "batch_size = 1\n",
    "mini_batch_size = 1\n",
    "eval_batch_size = 1\n",
    "\n",
    "eval_frequency = 2\n",
    "use_bn = False\n",
    "use_res = True\n",
    "learning_rate = 0.001\n",
    "g_alpha = 40\n",
    "g_lambda = 10\n",
    "g_beta = 10\n",
    "dropout = 0\n",
    "resize = None\n",
    "output_path = '/home/padamnoo/Desktop/Results/wgan_10k_640_zm_mm'\n",
    "output_path = '{}_batch{}_bn{}_dp{}_a{}_la{}_lr{}'.format(output_path, batch_size, int(use_bn), dropout, g_alpha, g_lambda, learning_rate)\n",
    "saved_filelists = 'std_sex_640_160_62.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    data_path = './'\n",
    "    output_path = 'results/' + output_path\n",
    "if platform.system() == 'Linux':\n",
    "    data_path = './'\n",
    "    output_path = 'results/' + output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = data_path + '/std96'\n",
    "saved_filelists = data_path + '/' + saved_filelists\n",
    "# load filenames\n",
    "# file_mat = sio.loadmat(saved_filelists)\n",
    "\n",
    "# load filenames\n",
    "data_path = '/home/padamnoo/Desktop/Data/ModelData/'\n",
    "train_list_T1 = glob.glob(data_path + 'train/T1/*')\n",
    "valid_list_T1 = glob.glob(data_path + 'valid/T1/*')\n",
    "train_list_T2 =glob.glob(data_path + 'train/T2/*')\n",
    "valid_list_T2 = glob.glob(data_path + 'valid/T2/*')\n",
    "# test_list = glob.glob(data_path + '/test/*_img.png')\n",
    "\n",
    "# set key for input images and labels\n",
    "org_suffix = '_img.png'\n",
    "lab_suffix = '_lab.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list_T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = {org_suffix: [ 'zero-mean', ('channelcheck', 1)],\n",
    "       lab_suffix: [('one-hot', [0, 63, 127, 191, 255]), ('channelcheck', 5)]\n",
    "       }\n",
    "\n",
    "pre_ = {org_suffix: [ 'zero-mean', ('channelcheck', 1)],\n",
    "        lab_suffix: [('one-hot', [0, 63, 127, 191, 255]), ('channelcheck', 5)]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SimpleImageProcessor(pre=pre)\n",
    "processor_no_p = SimpleImageProcessor(pre=pre_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_provider_T1_t = DataProvider(train_list_T1, [org_suffix, lab_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T1_t = DataProvider(valid_list_T1, [org_suffix, lab_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "train_provider_T1 = DataProvider(train_list_T1, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T1 = DataProvider(valid_list_T1, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "train_provider_T2 = DataProvider(train_list_T2, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T2 = DataProvider(valid_list_T2, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "\n",
    "\n",
    "train_provider_T1_t_w = DataProvider(train_list_T1, [org_suffix, lab_suffix],\n",
    "                                   is_pre_load=False,\n",
    "                                   is_shuffle=True,\n",
    "                                   # temp_dir=output_path,\n",
    "                                   processor=processor_no_p,\n",
    "                                is_aug=False)\n",
    "\n",
    "train_provider_T1_w = DataProvider(train_list_T1, [org_suffix],\n",
    "                                 is_pre_load=False,\n",
    "                                 is_shuffle=True,\n",
    "                                 # temp_dir=output_path,\n",
    "                                 processor=processor_no_p,\n",
    "                                   is_aug=False)\n",
    "\n",
    "train_provider_T2_w = DataProvider(train_list_T2, [org_suffix],\n",
    "                                  is_pre_load=False,\n",
    "                                  is_shuffle=True,\n",
    "                                  # temp_dir=output_path,\n",
    "                                  processor=processor_no_p,\n",
    "                                    is_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 23:53:50.655044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/padamnoo/.conda/envs/general/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-29 23:53:50.676992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/padamnoo/.conda/envs/general/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-01-29 23:53:50.677141: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-29 23:53:50.677528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(2, 4, 16, use_bn=use_bn)\n",
    "disc = Discriminator(1, 4, 16, use_bn=use_bn)\n",
    "model = GANModel([gen, disc], org_suffix, lab_suffix, g_alpha=g_alpha, g_lambda=g_lambda, g_beta=g_beta, dropout=0)\n",
    "gen_lr = StepDecayLearningRate(learning_rate=learning_rate,\n",
    "                           decay_step=10,\n",
    "                           decay_rate=0.8,\n",
    "                           data_size=train_provider_T1.size + train_provider_T2.size,\n",
    "                           batch_size=batch_size)\n",
    "disc_lr = StepDecayLearningRate(learning_rate=learning_rate,\n",
    "                           decay_step=10,\n",
    "                           decay_rate=0.8,\n",
    "                           data_size=train_provider_T1.size + train_provider_T2.size,\n",
    "                           batch_size=batch_size)\n",
    "gen_optimizer = tf.keras.optimizers.Adam(gen_lr)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(disc_lr)\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training: epochs 1, learning rate ['0.001', '0.001'], batch size 1, mini-batch size 1, training data 2588, validation data 576.\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(train_provider_T1, train_provider_T2, valid_provider_T1, valid_provider_T2, train_provider_T1_t, valid_provider_T1_t,\n\u001b[1;32m      3\u001b[0m                         train_provider_T1_w, train_provider_T2_w,train_provider_T1_t_w,\n\u001b[1;32m      4\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      5\u001b[0m                        batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m      6\u001b[0m                        mini_batch_size\u001b[39m=\u001b[39;49mmini_batch_size,\n\u001b[1;32m      7\u001b[0m                        output_path\u001b[39m=\u001b[39;49moutput_path,\n\u001b[1;32m      8\u001b[0m                        optimizer\u001b[39m=\u001b[39;49m[gen_optimizer, disc_optimizer],\n\u001b[1;32m      9\u001b[0m                        learning_rate\u001b[39m=\u001b[39;49m[gen_lr, disc_lr],\n\u001b[1;32m     10\u001b[0m                        eval_frequency\u001b[39m=\u001b[39;49meval_frequency)\n",
      "File \u001b[0;32m~/Desktop/Repositories/LMISA/core/trainer_tf_uni.py:109\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_provider_CT, train_provider_MRI, validation_provider_CT, validation_provider_MRI, train_provider_CT_t, validation_provider_CT_t, train_provider_CT_w, train_provider_MRI_w, train_provider_CT_t_w, epochs, batch_size, output_path, optimizer, learning_rate, mini_batch_size, eval_frequency, is_save_train_imgs, is_save_valid_imgs, strategy)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(feed_dict_CT))\n\u001b[1;32m     92\u001b[0m     \u001b[39m# savepath = 'D:/TensorFlow/WGAN_latent/test/'\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# lab = feed_dict_CT_lab['_lab.nii.gz']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[39m# lab = nib.Nifti1Image(lab.astype(np.float32), affine=temp_affine)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39m# nib.save(lab, os.path.join(savepath + 'lab'))\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     mini_grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_grads(feed_dict_CT, feed_dict_MRI, feed_dict_CT_lab)\n\u001b[1;32m    110\u001b[0m     grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grads_add(grads, mini_grads)\n\u001b[1;32m    111\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grads_div(grads, mini_iters)\n",
      "File \u001b[0;32m~/Desktop/Repositories/LMISA/model/model_wgan_uni.py:59\u001b[0m, in \u001b[0;36mGANModel.get_grads\u001b[0;34m(self, data_dict_CT, data_dict_MRI, feed_dict_CT_lab)\u001b[0m\n\u001b[1;32m     56\u001b[0m     disc_gen_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet[\u001b[39m1\u001b[39m](out_seg[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m1\u001b[39m:], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m     disc_real_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet[\u001b[39m1\u001b[39m](labs[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m1\u001b[39m:], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 59\u001b[0m     gen_loss, _, _, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gen_loss(disc_gen_logits, gen_logits, ys\n\u001b[1;32m     60\u001b[0m                                               , o_seg, labs)\n\u001b[1;32m     61\u001b[0m     disc_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_disc_loss(disc_real_logits, disc_gen_logits, gen_logits, ys, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[39m# gen_loss = gen_loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Repositories/LMISA/model/model_wgan_uni.py:228\u001b[0m, in \u001b[0;36mGANModel._get_gen_loss\u001b[0;34m(self, disc_gen_logits, gen_logits, ys, o_seg, labs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gen_loss\u001b[39m(\u001b[39mself\u001b[39m, disc_gen_logits, gen_logits, ys, o_seg, labs):\n\u001b[0;32m--> 228\u001b[0m     weight_map \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((tf\u001b[39m.\u001b[39mshape(ys)[\u001b[39m0\u001b[39m], tf\u001b[39m.\u001b[39mshape(ys)[\u001b[39m1\u001b[39m], tf\u001b[39m.\u001b[39mshape(ys)[\u001b[39m2\u001b[39m], tf\u001b[39m.\u001b[39mshape(ys)[\u001b[39m3\u001b[39m]), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mfloat)\n\u001b[1;32m    229\u001b[0m     labs[labs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    230\u001b[0m     gen_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtf\u001b[39m.\u001b[39mreduce_mean(disc_gen_logits)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/numpy/__init__.py:284\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "# train\n",
    "results = trainer.train(train_provider_T1, train_provider_T2, valid_provider_T1, valid_provider_T2, train_provider_T1_t, valid_provider_T1_t,\n",
    "                        train_provider_T1_w, train_provider_T2_w,train_provider_T1_t_w,\n",
    "                        epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       mini_batch_size=mini_batch_size,\n",
    "                       output_path=output_path,\n",
    "                       optimizer=[gen_optimizer, disc_optimizer],\n",
    "                       learning_rate=[gen_lr, disc_lr],\n",
    "                       eval_frequency=eval_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59755e8da6927cf21f67bd007f06a83a179a3477a85a1fac81fac80ea80004c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
