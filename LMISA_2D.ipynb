{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/padamnoo/.conda/envs/general/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "--xla_gpu_cuda_data_dir=/home/padamnoo/.conda/envs/general/\n"
     ]
    }
   ],
   "source": [
    "!echo $XLA_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "# sys.path.append('git/_framework')\n",
    "from utils import util as U\n",
    "from core.data_provider import DataProvider\n",
    "from core.trainer_tf_uni import Trainer\n",
    "from core.data_processor import SimpleImageProcessor\n",
    "from core.learning_rate import StepDecayLearningRate\n",
    "from model.model_wgan_uni import GANModel\n",
    "from model.gan_10k import Generator, Discriminator\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "epochs = 2\n",
    "batch_size = 1\n",
    "mini_batch_size = 1\n",
    "eval_batch_size = 1\n",
    "\n",
    "eval_frequency = 2\n",
    "use_bn = False\n",
    "use_res = True\n",
    "learning_rate = 0.001\n",
    "g_alpha = 40\n",
    "g_lambda = 10\n",
    "g_beta = 10\n",
    "dropout = 0\n",
    "resize = None\n",
    "output_path = '/home/padamnoo/Desktop/Results/wgan_10k_640_zm_mm'\n",
    "output_path = '{}_batch{}_bn{}_dp{}_a{}_la{}_lr{}'.format(output_path, batch_size, int(use_bn), dropout, g_alpha, g_lambda, learning_rate)\n",
    "saved_filelists = 'std_sex_640_160_62.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    data_path = './'\n",
    "    output_path = 'results/' + output_path\n",
    "if platform.system() == 'Linux':\n",
    "    data_path = './'\n",
    "    output_path = 'results/' + output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_path = data_path + '/std96'\n",
    "saved_filelists = data_path + '/' + saved_filelists\n",
    "# load filenames\n",
    "# file_mat = sio.loadmat(saved_filelists)\n",
    "\n",
    "# load filenames\n",
    "data_path = '/home/padamnoo/Desktop/Data/ModelDataPreprocessedResized/'\n",
    "train_list_T1 = glob.glob(data_path + 'train/T1/*')\n",
    "valid_list_T1 = glob.glob(data_path + 'valid/T1/*')\n",
    "train_list_T2 =glob.glob(data_path + 'train/T2/*')\n",
    "valid_list_T2 = glob.glob(data_path + 'valid/T2/*')\n",
    "# test_list = glob.glob(data_path + '/test/*_img.png')\n",
    "\n",
    "# set key for input images and labels\n",
    "org_suffix = '_img.png'\n",
    "lab_suffix = '_lab.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_list_T2) + len(valid_list_T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = {org_suffix: [ 'zero-mean', ('channelcheck', 1)],\n",
    "       lab_suffix: [('one-hot', [0, 63, 127, 191, 255]), ('channelcheck', 5)]\n",
    "}      \n",
    "\n",
    "pre_ = {org_suffix: [ 'zero-mean', ('channelcheck', 1)],\n",
    "        lab_suffix: [('one-hot', [0, 63, 127, 191, 255]), ('channelcheck', 5)]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SimpleImageProcessor(pre=pre)\n",
    "processor_no_p = SimpleImageProcessor(pre=pre_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_provider_T1_t = DataProvider(train_list_T1, [org_suffix, lab_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T1_t = DataProvider(valid_list_T1, [org_suffix, lab_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "train_provider_T1 = DataProvider(train_list_T1, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T1 = DataProvider(valid_list_T1, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "train_provider_T2 = DataProvider(train_list_T2, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        is_shuffle=True,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "valid_provider_T2 = DataProvider(valid_list_T2, [org_suffix],\n",
    "                        is_pre_load=False,\n",
    "                        # temp_dir=output_path,\n",
    "                        processor=processor)\n",
    "\n",
    "\n",
    "\n",
    "train_provider_T1_t_w = DataProvider(train_list_T1, [org_suffix, lab_suffix],\n",
    "                                   is_pre_load=False,\n",
    "                                   is_shuffle=True,\n",
    "                                   # temp_dir=output_path,\n",
    "                                   processor=processor_no_p,\n",
    "                                is_aug=False)\n",
    "\n",
    "train_provider_T1_w = DataProvider(train_list_T1, [org_suffix],\n",
    "                                 is_pre_load=False,\n",
    "                                 is_shuffle=True,\n",
    "                                 # temp_dir=output_path,\n",
    "                                 processor=processor_no_p,\n",
    "                                   is_aug=False)\n",
    "\n",
    "train_provider_T2_w = DataProvider(train_list_T2, [org_suffix],\n",
    "                                  is_pre_load=False,\n",
    "                                  is_shuffle=True,\n",
    "                                  # temp_dir=output_path,\n",
    "                                  processor=processor_no_p,\n",
    "                                    is_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_all_data',\n",
       " '_build_temp_folder',\n",
       " '_cur_i',\n",
       " '_file_list',\n",
       " '_is_aug',\n",
       " '_is_shuffle',\n",
       " '_load_data',\n",
       " '_load_temp_file',\n",
       " '_next_idx',\n",
       " '_org_suffix',\n",
       " '_other_suffix',\n",
       " '_processor',\n",
       " '_temp_dir',\n",
       " 'clipped_zoom',\n",
       " 'rotation',\n",
       " 'size']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 16:20:04.007198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 16:20:07.203306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22025 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2023-02-10 16:20:07.204049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22279 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2023-02-10 16:20:07.204516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22279 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2023-02-10 16:20:07.205058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22279 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3d:00.0, compute capability: 8.6\n",
      "2023-02-10 16:20:07.205536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 12725 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3e:00.0, compute capability: 8.6\n",
      "2023-02-10 16:20:07.206003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22279 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(2, 4, 16, use_bn=use_bn)\n",
    "disc = Discriminator(1, 4, 16, use_bn=use_bn)\n",
    "model = GANModel([gen, disc], org_suffix, lab_suffix, g_alpha=g_alpha, g_lambda=g_lambda, g_beta=g_beta, dropout=0)\n",
    "gen_lr = StepDecayLearningRate(learning_rate=learning_rate,\n",
    "                           decay_step=10,\n",
    "                           decay_rate=0.8,\n",
    "                           data_size=train_provider_T1.size + train_provider_T2.size,\n",
    "                           batch_size=batch_size)\n",
    "disc_lr = StepDecayLearningRate(learning_rate=learning_rate,\n",
    "                           decay_step=10,\n",
    "                           decay_rate=0.8,\n",
    "                           data_size=train_provider_T1.size + train_provider_T2.size,\n",
    "                           batch_size=batch_size)\n",
    "gen_optimizer = tf.keras.optimizers.Adam(gen_lr)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(disc_lr)\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training: epochs 2, learning rate ['0.001', '0.001'], batch size 1, mini-batch size 1, training data 2584, validation data 576.\n",
      "[[[[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]]\n",
      "\n",
      "\n",
      " [[[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]\n",
      "\n",
      "  [[ True]\n",
      "   [ True]\n",
      "   [ True]\n",
      "   ...\n",
      "   [ True]\n",
      "   [ True]\n",
      "   [ True]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 16:20:10.574155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-10 16:20:17.033768: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x53061d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-10 16:20:17.033819: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.033832: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.033842: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.033851: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.033860: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (4): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.033869: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (5): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-02-10 16:20:17.043385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-10 16:20:17.170470: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f1ffc733d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f1ffc733d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(train_provider_T1, train_provider_T2, valid_provider_T1, valid_provider_T2, train_provider_T1_t, valid_provider_T1_t,\n\u001b[1;32m      3\u001b[0m                         train_provider_T1_w, train_provider_T2_w,train_provider_T1_t_w,\n\u001b[1;32m      4\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      5\u001b[0m                        batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m      6\u001b[0m                        mini_batch_size\u001b[39m=\u001b[39;49mmini_batch_size,\n\u001b[1;32m      7\u001b[0m                        output_path\u001b[39m=\u001b[39;49moutput_path,\n\u001b[1;32m      8\u001b[0m                        optimizer\u001b[39m=\u001b[39;49m[gen_optimizer, disc_optimizer],\n\u001b[1;32m      9\u001b[0m                        learning_rate\u001b[39m=\u001b[39;49m[gen_lr, disc_lr],\n\u001b[1;32m     10\u001b[0m                        eval_frequency\u001b[39m=\u001b[39;49meval_frequency)\n",
      "File \u001b[0;32m~/Desktop/Repositories/LMISA/core/trainer_tf_uni.py:115\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_provider_CT, train_provider_MRI, validation_provider_CT, validation_provider_MRI, train_provider_CT_t, validation_provider_CT_t, train_provider_CT_w, train_provider_MRI_w, train_provider_CT_t_w, epochs, batch_size, output_path, optimizer, learning_rate, mini_batch_size, eval_frequency, is_save_train_imgs, is_save_valid_imgs, strategy)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(optimizer) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(grads), \u001b[39m'\u001b[39m\u001b[39mNumber of optimizer should equal to number of networks.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[39mfor\u001b[39;00m gi \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(grads)):\n\u001b[0;32m--> 115\u001b[0m         optimizer[gi]\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads[gi], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mnet[gi]\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m    116\u001b[0m         \u001b[39m# optimizer[gi] = strategy.experimental_run_v2(apply_gradients,(zip(grads[gi], self.model.net[gi].trainable_variables,)))\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mtrainable_variables))\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1140\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1139\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:634\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    633\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 634\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_apply_gradients(grads_and_vars)\n\u001b[1;32m    636\u001b[0m \u001b[39m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1166\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_apply_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars):\n\u001b[0;32m-> 1166\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply_gradients_fn,\n\u001b[1;32m   1168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution_strategy,\n\u001b[1;32m   1169\u001b[0m         grads_and_vars,\n\u001b[1;32m   1170\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1216\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1215\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1216\u001b[0m     distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m   1217\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[1;32m   1221\u001b[0m     _, var_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3717\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1211\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1211\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_step_xla(grad, var, \u001b[39mid\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_var_key(var)))\n\u001b[1;32m   1212\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/general/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "results = trainer.train(train_provider_T1, train_provider_T2, valid_provider_T1, valid_provider_T2, train_provider_T1_t, valid_provider_T1_t,\n",
    "                        train_provider_T1_w, train_provider_T2_w,train_provider_T1_t_w,\n",
    "                        epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       mini_batch_size=mini_batch_size,\n",
    "                       output_path=output_path,\n",
    "                       optimizer=[gen_optimizer, disc_optimizer],\n",
    "                       learning_rate=[gen_lr, disc_lr],\n",
    "                       eval_frequency=eval_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f534c629080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.device('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "59755e8da6927cf21f67bd007f06a83a179a3477a85a1fac81fac80ea80004c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
